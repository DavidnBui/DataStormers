{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9044f9be-2436-4faf-a02c-5f370791835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import hvplot.pandas\n",
    "import pandas as pd\n",
    "from utils import load_config, fetch_api_data, write_to_csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c09ef0-d6a3-4671-a972-ac7a16e58dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.ncdc.noaa.gov/swdiws\n",
    "# 'nx3tvs'       - (Point)   NEXRAD Level-3 Tornado Vortex Signatures\n",
    "# 'nx3meso'      - (Point)   NEXRAD Level-3 Mesocyclone Signatures\n",
    "# 'nx3hail'      - (Point)   NEXRAD Level-3 Hail Signatures\n",
    "# 'nx3structure' - (Point)   NEXRAD Level-3 Storm Cell Structure Information\n",
    "# 'warn'         - (Polygon) Severe Thunderstorm, Tornado, Flash Flood and Special Marine warnings\n",
    "datasets = [\"nx3tvs\"]\n",
    "outputFormat = \"json\"\n",
    "daterange = \"20240701:20240731\"  # \"periodOfRecord\"\n",
    "\n",
    "for dataset in datasets:\n",
    "    base_url = f\"https://www.ncdc.noaa.gov/swdiws/{outputFormat}/{dataset}/{daterange}\"\n",
    "    filename = f\"swdiws_{dataset}.csv\"\n",
    "\n",
    "    data = fetch_api_data(base_url)\n",
    "    #print(json.dumps(data, indent=2))\n",
    "    #print(data)\n",
    "\n",
    "    if data and \"result\" in data:\n",
    "        write_to_csv(data[\"result\"], filename, \"w\")\n",
    "    else:\n",
    "        print(f\"No data found or invalid response format for dataset: {dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360eb0f5-016b-43b0-acb2-0437f6e62f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'nx3tvs'       - (Point)   NEXRAD Level-3 Tornado Vortex Signatures\n",
    "# 'nx3meso'      - (Point)   NEXRAD Level-3 Mesocyclone Signatures\n",
    "# 'nx3hail'      - (Point)   NEXRAD Level-3 Hail Signatures\n",
    "# 'nx3structure' - (Point)   NEXRAD Level-3 Storm Cell Structure Information\n",
    "# 'warn'         - (Polygon) Severe Thunderstorm, Tornado, Flash Flood and Special Marine warnings\n",
    "datasets = [\"nx3tvs\"]\n",
    "outputFormat = \"geojson\"\n",
    "daterange = \"20240701:20240731\"  # \"periodOfRecord\"\n",
    "numResults = 2500\n",
    "\n",
    "# Initialize an empty list to store merged data\n",
    "merged_data_list = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    base_url = f\"https://www.ncdc.noaa.gov/swdiws/{outputFormat}/{dataset}/{daterange}/{numResults}\"\n",
    "    filename = f\"swdiws_{dataset}_{outputFormat}.csv\"\n",
    "\n",
    "    data = fetch_api_data(base_url)\n",
    "    # Data is nested, retrieve \"features\" dictionary\n",
    "    rows = data[\"features\"]\n",
    "    \n",
    "    # Iterate over each record in rows as that is nested as well\n",
    "    for record in rows:\n",
    "       # Merge the 'properties' and 'geometry' dictionaries\n",
    "        merged_data = {**record[\"properties\"], **record[\"geometry\"]}\n",
    "        # Append the merged data to the list\n",
    "        merged_data_list.append(merged_data)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    merged_df = pd.DataFrame(merged_data_list)\n",
    "\n",
    "# Split the coordinates column into latitude and longitude\n",
    "merged_df[['longitude', 'latitude']] = pd.DataFrame(merged_df['coordinates'].tolist(), index=merged_df.index)\n",
    "# Drop the original coordinates column\n",
    "merged_df = merged_df.drop(columns=['coordinates'])\n",
    "merged_df.head(25)\n",
    "\n",
    "    # if data and \"features\" in data:\n",
    "    #     write_to_csv(data[\"features\"], filename, \"w\")\n",
    "    # else:\n",
    "    #     print(f\"No data found or invalid response format for dataset: {dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690d44b1-e401-4520-ac71-66b15befedc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'MXDV' to numeric, forcing errors to NaN if conversion fails\n",
    "merged_df['MXDV'] = pd.to_numeric(merged_df['MXDV'], errors='coerce')\n",
    "# Ensure 'WSR_ID' is treated as a string\n",
    "merged_df['WSR_ID'] = merged_df['WSR_ID'].astype(str)\n",
    "merged_df.to_csv('swdiws_nx3tvs_geojson.csv', index=False)\n",
    "print(merged_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164772a6-f90b-4050-b695-853042652b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.fema.gov/about/openfema/data-sets\n",
    "base_url = f\"https://www.fema.gov/api/open/v2/\"\n",
    "\n",
    "params = {\"$count\": \"true\",\n",
    "          \"$filter\": \"incidentType eq 'Tornado'\"}\n",
    "\n",
    "endpoint = \"DisasterDeclarationsSummaries\"\n",
    "filename = f\"{endpoint}.csv\"\n",
    "endpoint_url = f\"{base_url}{endpoint}\"\n",
    "\n",
    "data = fetch_api_data(endpoint_url, params)\n",
    "#print(json.dumps(data, indent=2))\n",
    "tornado_summary_df = pd.DataFrame(data[\"DisasterDeclarationsSummaries\"])\n",
    "write_to_csv(data[\"DisasterDeclarationsSummaries\"], filename, \"w\")\n",
    "\n",
    "disaster_numbers = tornado_summary_df.disasterNumber.unique()\n",
    "formatted_disaster_numbers = ', '.join(f'{num}' for num in disaster_numbers)\n",
    "formatted_disaster_numbers\n",
    "\n",
    "    #disasterNumber\n",
    "#tornado_newer_df = tornado_df[tornado_df[\"declarationDate\"] > \"2019-12-31\"]\n",
    "#tornado_df.groupby(by=\"disasterNumber\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f45601a-61bb-4d5a-ae50-57eacca5cff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"$count\": \"true\",\n",
    "          \"$filter\": f\"disasterNumber in ({formatted_disaster_numbers})\"}\n",
    "\n",
    "endpoint = \"HousingAssistanceOwners\"\n",
    "filename = f\"{endpoint}.csv\"\n",
    "endpoint_url = f\"{base_url}{endpoint}\"\n",
    "data = fetch_api_data(endpoint_url, params)\n",
    "#print(json.dumps(data, indent=2))\n",
    "housing_assistance_df = pd.DataFrame(data[\"HousingAssistanceOwners\"])\n",
    "write_to_csv(data[\"HousingAssistanceOwners\"], filename, \"w\")\n",
    "housing_assistance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d4ba3c-db45-4f13-a6b0-e713a5a87f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "# Configure the map plot\n",
    "tornadoes_plot = merged_df.hvplot.points(\n",
    "    \"longitude\",\n",
    "    \"latitude\",\n",
    "    geo=True,\n",
    "    tiles=\"OSM\",\n",
    "    frame_width=800,\n",
    "    frame_height=600,\n",
    "    size=\"MXDV\",\n",
    "    color=\"WSR_ID\"\n",
    ")\n",
    "\n",
    "# Display the map\n",
    "tornadoes_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2162b8eb-f456-4ed2-b051-a947af199832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataCleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc02785-46aa-4dd6-af22-0c496da8a077",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df\n",
    "\n",
    "# Standardize column names to lowercase\n",
    "merged_df.columns = [col.lower() for col in merged_df.columns]\n",
    "\n",
    "#dropped cell and cell id columns\n",
    "merged_df.drop(columns=['cell_type', 'cell_id',], inplace=True)\n",
    "\n",
    "#renamed columns \n",
    "#max_shear = change in wind speed and direction with height in the atmosphere\n",
    "#wsr_id = weather stations\n",
    "#mxdv = maximum difference in velocity, particularly within areas of rotation\n",
    "#ztime = time of the event\n",
    "#azimuth = direction in which the tornado is moving\n",
    "merged_df.rename(columns={\n",
    "    'max_shear': 'wind_speed',\n",
    "    'wsr_id': 'radar_id',\n",
    "    'mxdv': 'velocity',\n",
    "    'ztime': 'event_time',\n",
    "    'azimuth': 'directional_movement',\n",
    "}, inplace=True)\n",
    "\n",
    "# Convert 'ztime' column to datetime\n",
    "merged_df['event_time'] = pd.to_datetime(merged_df['event_time'])\n",
    "\n",
    "# Check for missing values\n",
    "print(merged_df.isnull().sum())\n",
    "\n",
    "# Remove duplicates\n",
    "merged_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Display the cleaned dataframe\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19f15c4-e586-4a8b-9128-0b4f4a7f9ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_assistance_df\n",
    "\n",
    "#Made columns names lowercase\n",
    "housing_assistance_df.columns = housing_assistance_df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "#dropped unused columns\n",
    "housing_assistance_df.drop(columns=['id', \n",
    "                                    'nofemainspecteddamage', \n",
    "                                    'disasternumber',\n",
    "                                    'validregistrations', \n",
    "                                    'averagefemainspecteddamage', \n",
    "                                    'totalinspected',\n",
    "                                   'femainspecteddamagebetween1and10000',\n",
    "                                    'femainspecteddamagebetween10001and20000',\n",
    "                                    'femainspecteddamagebetween20001and30000',\n",
    "                                    'femainspecteddamagegreaterthan30000',\n",
    "                                    'approvedbetween1and10000',\n",
    "                                    'approvedbetween10001and25000', \n",
    "                                    'approvedbetween25001andmax'], inplace=True)\n",
    "\n",
    "#renaming columns\n",
    "#approvedforfemaassistance = number of applications that have been approved for FEMA assistance\n",
    "#totalapprovedihpamount = total amount of money approved under the FEMA Individual and Households Program (IHP)\n",
    "#repairreplaceamount = amount of money approved or provided for repair or replacement of damaged property\n",
    "#rentalamount = amount of money approved or provided for rental assistance\n",
    "#otherneedsamount = amount of money approved or provided for other necessary expenses\n",
    "#totalmaxgrants = amount of grants approved or provided to an individual or household\n",
    "\n",
    "housing_assistance_df.rename(columns={\n",
    "    'approvedforfemaassistance': 'approvedapplicants',\n",
    "    'totalapprovedihpamount': 'approvedbudget',\n",
    "    'repairreplaceamount': 'repairs',\n",
    "    'rentalamount': 'rentalbudget',\n",
    "    'otherneedsamount': 'misc.budget',\n",
    "    'totalmaxgrants': 'grants'\n",
    "}, inplace=True)\n",
    "\n",
    "#Gets rid of description in county column\n",
    "housing_assistance_df['county'] = housing_assistance_df['county'].str.replace(' \\(County\\)', '', regex=True)\n",
    "\n",
    "#Sets state and county as index\n",
    "housing_assistance_df.set_index(['state', 'county'], inplace=True)\n",
    "\n",
    "#Gets rid of rows in the totaldamage column that have a value of 0\n",
    "housing_assistance_df[housing_assistance_df['totaldamage'] != 0]\n",
    "\n",
    "# Remove any NaN values\n",
    "housing_assistance_df = housing_assistance_df.copy()\n",
    "housing_assistance_df.dropna(inplace=True)\n",
    "housing_assistance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b73346-b3d1-4ba3-b4cd-f8730651f072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
