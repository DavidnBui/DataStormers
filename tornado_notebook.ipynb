{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import json\n",
    "import sys\n",
    "\n",
    "# Third-party library imports\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "from IPython.display import display\n",
    "\n",
    "# Local application imports\n",
    "from utils import fetch_api_data, load_config, write_to_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch and process data from the NOAA's Severe Weather Data Inventory (SWDI) API. \n",
    "\n",
    "### Key Components:\n",
    "\n",
    "- **Datasets**: Currently, only the `nx3tvs` dataset is specified, which corresponds to NEXRAD Level-3 Tornado Vortex Signatures.\n",
    "- **Output Format**: Data is requested in JSON format (`outputFormat = \"json\"`).\n",
    "- **Date Range**: The data is queried for the period from July 1, 2024, to July 31, 2024 (`daterange = \"20240701:20240731\"`).\n",
    "\n",
    "### Process:\n",
    "1. **URL Construction**: A base URL is created for each dataset using the format `https://www.ncdc.noaa.gov/swdiws/{outputFormat}/{dataset}/{daterange}`.\n",
    "2. **Data Fetching**: The `fetch_api_data()` function is used to retrieve data from the constructed URL.\n",
    "3. **Data Handling**:\n",
    "   - If data is successfully fetched and contains results, it is written to a CSV file named `swdiws_{dataset}.csv`.\n",
    "   - If no data is found or the response format is invalid, an error message is printed.\n",
    "\n",
    "For more information about the datasets and their definitions, visit [NOAA SWDI](https://www.ncdc.noaa.gov/swdiws)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Available datasets ###\n",
    "# 'nx3tvs'       - (Point)   NEXRAD Level-3 Tornado Vortex Signatures\n",
    "# 'nx3meso'      - (Point)   NEXRAD Level-3 Mesocyclone Signatures\n",
    "# 'nx3hail'      - (Point)   NEXRAD Level-3 Hail Signatures\n",
    "# 'nx3structure' - (Point)   NEXRAD Level-3 Storm Cell Structure Information\n",
    "# 'warn'         - (Polygon) Severe Thunderstorm, Tornado, Flash Flood and Special Marine warnings\n",
    "#\n",
    "# ':inv' may be added to any dataset name to display the inventory of available data for that dataset.  For example 'nx3tvs:inv'.\n",
    "\n",
    "### Output formats ###\n",
    "# 'json' - JSON is commonly used in web application development and is widely supported by many programming languages.\n",
    "# 'csv' - Comma-separated plain text which can be opened in MS Excel, OpenOffice, ArcGIS, etc...\n",
    "# 'xml' - XML which can be opened in MS Excel, OpenOffice, etc...\n",
    "# 'shp' - A .zip file containing the 4 ESRI Shapefile files (.shp, .shx, .dbf, .prj)\n",
    "# 'kmz' - KMZ file which can be opened in Virtual Globe software such as Google Earth\n",
    "\n",
    "# Define the list of datasets to fetch\n",
    "datasets = [\"nx3tvs\"]  # NEXRAD Level-3 Tornado Vortex Signatures\n",
    "\n",
    "# Specify the desired output format for the data\n",
    "outputFormat = \"geojson\"  # Data will be fetched in GEOJSON format\n",
    "\n",
    "# Define the date range for the data query\n",
    "daterange = \"20240701:20240731\"  # Data for July 2024\n",
    "\n",
    "# Define the number of results to return\n",
    "numResults = 2500\n",
    "\n",
    "# Initialize an empty list to store merged data\n",
    "merged_data_list = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    base_url = f\"https://www.ncdc.noaa.gov/swdiws/{outputFormat}/{dataset}/{daterange}/{numResults}\"\n",
    "    filename = f\"data/swdiws_{dataset}_{outputFormat}.csv\"\n",
    "\n",
    "    data = fetch_api_data(base_url)\n",
    "    # Data is nested, retrieve \"features\" dictionary\n",
    "    rows = data[\"features\"]\n",
    "    \n",
    "    # Iterate over each record in rows as that is nested as well\n",
    "    for record in rows:\n",
    "       # Merge the 'properties' and 'geometry' dictionaries\n",
    "        merged_data = {**record[\"properties\"], **record[\"geometry\"]}\n",
    "        # Append the merged data to the list\n",
    "        merged_data_list.append(merged_data)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    swdiws_tornado_data_df = pd.DataFrame(merged_data_list)\n",
    "\n",
    "# Split the coordinates column into latitude and longitude\n",
    "swdiws_tornado_data_df[['longitude', 'latitude']] = pd.DataFrame(swdiws_tornado_data_df['coordinates'].tolist(), index=swdiws_tornado_data_df.index)\n",
    "# Drop the original coordinates column\n",
    "swdiws_tornado_data_df = swdiws_tornado_data_df.drop(columns=['coordinates'])\n",
    "\n",
    "# Convert 'MXDV' to numeric, forcing errors to NaN if conversion fails\n",
    "swdiws_tornado_data_df['MXDV'] = pd.to_numeric(swdiws_tornado_data_df['MXDV'], errors='coerce')\n",
    "# Ensure 'WSR_ID' is treated as a string\n",
    "swdiws_tornado_data_df['WSR_ID'] = swdiws_tornado_data_df['WSR_ID'].astype(str)\n",
    "# Save the DataFrame to a CSV file\n",
    "swdiws_tornado_data_df.to_csv(filename, index=False)\n",
    "\n",
    "swdiws_tornado_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch and process data on tornado-related disaster declarations from FEMA's OpenFEMA API.\n",
    "\n",
    "### Key Steps:\n",
    "1. **API Request**:\n",
    "   - Constructs the API request URL for the `DisasterDeclarationsSummaries` endpoint at `https://www.fema.gov/api/open/v2/`.\n",
    "   - Filters the data to include only incidents where `incidentType` is 'Tornado'.\n",
    "\n",
    "2. **Data Retrieval and Saving**:\n",
    "   - Fetches data from the API.\n",
    "   - Converts the data into a DataFrame.\n",
    "   - Saves the DataFrame to a CSV file named `DisasterDeclarationsSummaries.csv`.\n",
    "\n",
    "For more details on FEMA datasets, visit [OpenFEMA Data Sets](https://www.fema.gov/about/openfema/data-sets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL for FEMA's OpenFEMA API\n",
    "base_url = f\"https://www.fema.gov/api/open/v2/\"\n",
    "\n",
    "# Parameters for the API request:\n",
    "# - $count: To get the count of records matching the filter\n",
    "# - $filter: Filters the data to include only 'Tornado' incidents\n",
    "params = {\"$count\": \"true\",\n",
    "          \"$filter\": \"incidentType eq 'Tornado'\"}\n",
    "\n",
    "# Endpoint for the API request\n",
    "endpoint = \"DisasterDeclarationsSummaries\"\n",
    "# Filename to save the data\n",
    "filename = f\"data/{endpoint}.csv\"\n",
    "# Construct the full URL for the API request\n",
    "endpoint_url = f\"{base_url}{endpoint}\"\n",
    "\n",
    "# Fetch data from the API\n",
    "data = fetch_api_data(endpoint_url, params)\n",
    "\n",
    "# Convert the fetched data to a DataFrame\n",
    "disaster_declarations_df = pd.DataFrame(data[\"DisasterDeclarationsSummaries\"])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "write_to_csv(data[\"DisasterDeclarationsSummaries\"], filename, \"w\")\n",
    "\n",
    "disaster_declarations_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch and process data on housing assistance owners related to previously identified tornado disaster declarations from FEMA's OpenFEMA API.\n",
    "\n",
    "### Key Steps:\n",
    "1. **Extract and Format Disaster Numbers**:\n",
    "   - Retrieves unique disaster numbers from the `disaster_declarations_df` DataFrame.\n",
    "   - Formats these numbers into a comma-separated string for use in the API request.\n",
    "\n",
    "2. **API Request**:\n",
    "   - Constructs parameters to filter the data by the formatted disaster numbers.\n",
    "   - Defines the endpoint for fetching housing assistance records.\n",
    "\n",
    "3. **Data Retrieval and Saving**:\n",
    "   - Fetches data from the API.\n",
    "   - Converts the data into a DataFrame.\n",
    "   - Saves the DataFrame to a CSV file named `HousingAssistanceOwners.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique disaster numbers from the disaster_declarations_df DataFrame\n",
    "disaster_numbers = disaster_declarations_df.disasterNumber.unique()\n",
    "# Format the disaster numbers into a comma-separated string for use in the API filter\n",
    "formatted_disaster_numbers = ', '.join(f'{num}' for num in disaster_numbers)\n",
    "\n",
    "# Define parameters for the API request:\n",
    "# - $count: To get the count of records matching the filter\n",
    "# - $filter: Filters the data to include only records with disaster numbers from the formatted list\n",
    "params = {\"$count\": \"true\",\n",
    "          \"$filter\": f\"disasterNumber in ({formatted_disaster_numbers})\"}\n",
    "\n",
    "# Endpoint for the API request\n",
    "endpoint = \"HousingAssistanceOwners\"\n",
    "# Filename to save the data\n",
    "filename = f\"data/{endpoint}.csv\"\n",
    "# Construct the full URL for the API request\n",
    "endpoint_url = f\"{base_url}{endpoint}\"\n",
    "\n",
    "# Fetch data from the API\n",
    "data = fetch_api_data(endpoint_url, params)\n",
    "\n",
    "# Convert the fetched data to a DataFrame\n",
    "housing_assistance_df = pd.DataFrame(data[\"HousingAssistanceOwners\"])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "write_to_csv(data[\"HousingAssistanceOwners\"], filename, \"w\")\n",
    "\n",
    "housing_assistance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration from a JSON file\n",
    "config = load_config('config.json')\n",
    "\n",
    "# Retrieve the Census API key from the configuration\n",
    "census_api_key = config.get('Census', {}).get('key')\n",
    "\n",
    "# Check if the API key was found in the configuration\n",
    "if not census_api_key:\n",
    "    print(\"Census API key not found in the configuration file.\")\n",
    "    sys.exit()  # Exit the script if the key is missing\n",
    "\n",
    "# Set up parameters for the API request\n",
    "params = {\n",
    "    \"get\": \"NAME,P1_001N\",   # Request state names and population counts\n",
    "    \"for\": \"state:*\",        # Specify that the data should be for all states\n",
    "    \"key\": census_api_key    # Include the API key in the request\n",
    "}\n",
    "\n",
    "# Correct URL to fetch population data for all states (2020 Census data)\n",
    "base_url = \"https://api.census.gov/data/2020/dec/pl\"\n",
    "\n",
    "# Fetch data from the API using the base URL and parameters\n",
    "data = fetch_api_data(base_url, params)\n",
    "\n",
    "# Try to parse JSON data\n",
    "try:\n",
    "    # The first item in the JSON response is the column names\n",
    "    columns = data[0]\n",
    "    \n",
    "    # Convert the remaining JSON data into a DataFrame\n",
    "    population_data = pd.DataFrame(data[1:], columns=columns)    \n",
    "    # Convert the population column to numeric and rename it\n",
    "    population_data['population'] = pd.to_numeric(population_data['P1_001N'])\n",
    "    # Select only the desired columns (NAME and population)\n",
    "    census_population_df = population_data[['NAME', 'population']]\n",
    "    # Save the cleaned DataFrame to a CSV file\n",
    "    census_population_df.to_csv('data/census_population.csv', index=False)\n",
    "\n",
    "except ValueError as e:\n",
    "    # Handle JSON decoding errors\n",
    "    print(\"JSON Decode Error:\", e)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify the data\n",
    "census_population_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map full state names to abbreviations\n",
    "state_abbrev_map = {\n",
    "    'ALABAMA': 'AL', 'ALASKA': 'AK', 'ARIZONA': 'AZ', 'ARKANSAS': 'AR',\n",
    "    'CALIFORNIA': 'CA', 'COLORADO': 'CO', 'CONNECTICUT': 'CT', 'DELAWARE': 'DE',\n",
    "    'FLORIDA': 'FL', 'GEORGIA': 'GA', 'HAWAII': 'HI', 'IDAHO': 'ID',\n",
    "    'ILLINOIS': 'IL', 'INDIANA': 'IN', 'IOWA': 'IA', 'KANSAS': 'KS',\n",
    "    'KENTUCKY': 'KY', 'LOUISIANA': 'LA', 'MAINE': 'ME', 'MARYLAND': 'MD',\n",
    "    'MASSACHUSETTS': 'MA', 'MICHIGAN': 'MI', 'MINNESOTA': 'MN', 'MISSISSIPPI': 'MS',\n",
    "    'MISSOURI': 'MO', 'MONTANA': 'MT', 'NEBRASKA': 'NE', 'NEVADA': 'NV',\n",
    "    'NEW HAMPSHIRE': 'NH', 'NEW JERSEY': 'NJ', 'NEW MEXICO': 'NM', 'NEW YORK': 'NY',\n",
    "    'NORTH CAROLINA': 'NC', 'NORTH DAKOTA': 'ND', 'OHIO': 'OH', 'OKLAHOMA': 'OK',\n",
    "    'OREGON': 'OR', 'PENNSYLVANIA': 'PA', 'RHODE ISLAND': 'RI', 'SOUTH CAROLINA': 'SC',\n",
    "    'SOUTH DAKOTA': 'SD', 'TENNESSEE': 'TN', 'TEXAS': 'TX', 'UTAH': 'UT',\n",
    "    'VERMONT': 'VT', 'VIRGINIA': 'VA', 'WASHINGTON': 'WA', 'WEST VIRGINIA': 'WV',\n",
    "    'WISCONSIN': 'WI', 'WYOMING': 'WY'\n",
    "}\n",
    "\n",
    "# Ensure the state names in the DataFrame are uppercase\n",
    "census_population_df.loc[:, 'NAME'] = census_population_df['NAME'].str.upper()\n",
    "\n",
    "# Map the state names in the population data to abbreviations\n",
    "census_population_df.loc[:, 'state'] = census_population_df['NAME'].map(state_abbrev_map)\n",
    "#census_population_df.head()\n",
    "\n",
    "tornado_severity_by_state = disaster_declarations_df.groupby('state')['declarationTitle'].count().reset_index()\n",
    "tornado_severity_by_state.rename(columns={'declarationTitle': 'severity'}, inplace=True)\n",
    "# Now try to merge using the new state_abbrev column\n",
    "merged_data = pd.merge(census_population_df, tornado_severity_by_state, on='state', how='inner')\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize column names to lowercase\n",
    "swdiws_tornado_data_df.columns = [col.lower() for col in swdiws_tornado_data_df.columns]\n",
    "\n",
    "#dropped cell and cell id columns\n",
    "swdiws_tornado_data_df.drop(columns=['cell_type', 'cell_id',], inplace=True)\n",
    "\n",
    "#renamed columns \n",
    "#max_shear = change in wind speed and direction with height in the atmosphere\n",
    "#wsr_id = weather stations\n",
    "#mxdv = maximum difference in velocity, particularly within areas of rotation\n",
    "#ztime = time of the event\n",
    "#azimuth = direction in which the tornado is moving\n",
    "swdiws_tornado_data_df.rename(columns={\n",
    "    'max_shear': 'wind_speed',\n",
    "    'wsr_id': 'radar_id',\n",
    "    'mxdv': 'velocity',\n",
    "    'ztime': 'event_time',\n",
    "    'azimuth': 'directional_movement',\n",
    "}, inplace=True)\n",
    "\n",
    "# Convert 'ztime' column to datetime\n",
    "swdiws_tornado_data_df['event_time'] = pd.to_datetime(swdiws_tornado_data_df['event_time'])\n",
    "\n",
    "# Remove duplicates\n",
    "swdiws_tornado_data_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Display the cleaned dataframe\n",
    "swdiws_tornado_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the radar locations data\n",
    "radar_locations_df = pd.read_csv('data/radar_locations.csv')\n",
    "\n",
    "# Merge the DataFrames\n",
    "radar_locations_merge_df = swdiws_tornado_data_df.merge(radar_locations_df, on='radar_id', how='left')\n",
    "\n",
    "# Keep only the relevant columns\n",
    "columns_to_keep = ['longitude', 'latitude', 'radar_id', 'city', 'state', 'range']\n",
    "radar_locations_merge_df = radar_locations_merge_df[columns_to_keep]\n",
    "\n",
    "# Map the state names in the DataFrame to abbreviations\n",
    "valid_states = set(state_abbrev_map.values())\n",
    "radar_locations_merge_df = radar_locations_merge_df[radar_locations_merge_df['state'].isin(valid_states)]\n",
    "\n",
    "\n",
    "# Find the record with the minimum range for each radar_id\n",
    "# Group by 'radar_id' and then use idxmin to get the index of the minimum range in each group\n",
    "min_range_indices = radar_locations_merge_df.groupby('radar_id')['range'].idxmin()\n",
    "\n",
    "# Use the indices to select the rows with the minimum range\n",
    "radar_locations_min_range_df = radar_locations_merge_df.loc[min_range_indices]\n",
    "\n",
    "radar_locations_min_range_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "\n",
    "# Configure the map plot\n",
    "radar_locations_plot = radar_locations_min_range_df.hvplot.points(\n",
    "    \"longitude\",\n",
    "    \"latitude\",\n",
    "    geo=True,\n",
    "    tiles=\"OSM\",\n",
    "    frame_width=800,\n",
    "    frame_height=600,\n",
    "    color=\"radar_id\",\n",
    "    hover_cols=['city', 'state']\n",
    ")\n",
    "\n",
    "# Display the map\n",
    "radar_locations_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Check if the DataFrame is not empty\n",
    "    if swdiws_tornado_data_df.empty:\n",
    "        print(\"The DataFrame is empty. No data to plot.\")\n",
    "    else:\n",
    "        # Create a base map centered around the mean latitude and longitude\n",
    "        base_map = folium.Map(location=[swdiws_tornado_data_df['latitude'].mean(), swdiws_tornado_data_df['longitude'].mean()], zoom_start=6)\n",
    "\n",
    "        # Prepare data for the heatmap\n",
    "        heat_data = [[row['latitude'], row['longitude']] for index, row in swdiws_tornado_data_df.iterrows()]\n",
    "\n",
    "        # Add the heatmap to the base map\n",
    "        HeatMap(heat_data).add_to(base_map)\n",
    "\n",
    "        # Display the map inline\n",
    "        display(base_map)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heat Map: Tornado Activity\n",
    "Explanation: Start with the heat map to provide a spatial overview of tornado activity. The heat map shows where tornadoes are most frequent across the U.S., using a color gradient to indicate higher concentrations of tornadoes.\n",
    "\n",
    "Why Important: This visualization sets the stage by identifying regions most affected by tornadoes. It helps understand where tornado activity is most intense, which is crucial for correlating with housing damage and financial assistance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Summary: The heat map visualizes tornado activity based on latitude and longitude coordinates. It displays regions with higher concentrations of tornado events using a color gradient.\n",
    "\n",
    "* Analysis:\n",
    "The heat map provides a spatial representation of tornado activity across the United States. Areas with higher concentrations of tornadoes are highlighted in warmer colors, indicating regions with more frequent or severe tornado events. This visualization helps in identifying geographic patterns of tornado activity, allowing for targeted preparedness and response efforts. It visually underscores the impact of tornadoes in specific regions, which can be crucial for emergency planning and resource allocation.\n",
    "\n",
    "* This code generates an interactive heatmap using Folium to visualize the geographical distribution of tornado damage. Each point on the map represents tornado damage locations, with areas of higher damage intensity shown in warmer colors.\n",
    "\n",
    "* Helps in identifying high-impact regions and understanding spatial patterns of tornado damage across the US. This visual representation is crucial for assessing which areas require more attention or resources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate data by state\n",
    "state_damage = disaster_declarations_df.groupby('state').size().sort_values(ascending=False)\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=state_damage.index, y=state_damage.values, color='steelblue')  # Removed palette, added color\n",
    "plt.title('Number of Tornadoes by State')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Number of Tornadoes')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bar Chart: Number of Tornadoes by State\n",
    "Explanation: Follow with the bar chart displaying the number of tornadoes that occurred in each state. This chart provides a detailed count of tornado occurrences, allowing for a comparison between states.\n",
    "\n",
    "Why Important: This bar chart adds granularity to the heat map by quantifying tornado events in each state. Comparing this with the heat map helps in understanding the specific tornado activity in high-frequency areas and can be used to correlate with damage and response data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This bar chart shows the number of tornadoes that occurred in each state. The states are sorted by the number of tornadoes, providing a clear comparison of tornado frequency across the US.\n",
    "\n",
    "* Helps to identify which states are most affected by tornadoes. This information is crucial for assessing tornado impact and prioritizing emergency preparedness and response efforts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert declarationDate to datetime\n",
    "disaster_declarations_df['declarationDate'] = pd.to_datetime(disaster_declarations_df['declarationDate'])\n",
    "\n",
    "# Group by year\n",
    "yearly_declarations = disaster_declarations_df.groupby(disaster_declarations_df['declarationDate'].dt.year).size()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "yearly_declarations.plot(kind='line', marker='o', color='b')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Declarations')\n",
    "plt.title('Disaster Declarations Over Time')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line Plot: Trend of Disaster Declarations Over Time\n",
    "Explanation: Present the line plot showing the trend of disaster declarations over the years. This graph illustrates how the frequency of disaster declarations has changed over time.\n",
    "\n",
    "Why Important: The line plot provides context on disaster trends and helps link historical data with current tornado activity. It offers insight into whether increased tornado activity corresponds with more disaster declarations, reflecting on data collection and awareness over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This line plot shows the trend of disaster declarations over the years. By grouping the data by year, it visualizes how the frequency of disaster declarations has changed over time.\n",
    "\n",
    "* Benefit: Useful for identifying trends or patterns in disaster declarations, such as whether certain years had more frequent or severe events. This information can be valuable for analyzing changes in disaster frequency and planning future responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate damage data by state\n",
    "state_damage = housing_assistance_df.groupby('state')['totalDamage'].sum().sort_values(ascending=False)\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=state_damage.index, y=state_damage.values, color='steelblue')  # Removed palette, added color\n",
    "plt.title('Total Housing Damage by State')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Total Damage ($)')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bar Chart: Total Housing Damage by State\n",
    "Explanation: Conclude with the bar chart displaying the total housing damage reported by state. This chart shows the financial impact of tornadoes on housing in different states.\n",
    "\n",
    "Why Important: This bar chart ties together the tornado activity with financial impact, showing which states experience the highest damage. It is crucial for understanding the correlation between tornado frequency and housing damage and assessing the effectiveness of financial assistance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This pie chart illustrates the distribution of various types of housing assistance amounts provided. It shows the proportion of total approved assistance, repair and replace amounts, rental amounts, and other needs amounts.\n",
    "\n",
    "* **Total Approved IHP Amount**: This represents the total amount of money approved for the **Individuals and Households Program (IHP)**. This program helps people affected by disasters to cover necessary expenses and serious needs that insurance or other forms of assistance don’t cover.\n",
    "\n",
    "* **Repair/Replace Amount**: This portion of the funds is specifically allocated to repairing or replacing damaged homes.\n",
    "\n",
    "* **Rental Amount**: This represents funds provided to cover temporary housing expenses while homes are being repaired or replaced.\n",
    "\n",
    "* **Other Needs Amount**: This includes funds for essential items like medical expenses, transportation, and other serious disaster-related needs.\n",
    "\n",
    "* Benefit: Provides a clear picture of how housing assistance is allocated among different categories. This helps in understanding which types of assistance are most prevalent and can guide resource allocation and policy-making.\n",
    "\n",
    "* Analysis:\n",
    "The pie chart shows that **50% of the housing assistance funds are allocated to the Total Approved IHP Amount**, with 36% directed towards Repair/Replace Amounts.**This indicates a significant focus on broad, comprehensive support through the IHP, ensuring that a wide range of needs are covered for those affected by disasters.** The substantial portion directed towards repairs and replacements highlights the importance of restoring homes, reflecting the critical need for housing stability in disaster recovery. Understanding this distribution helps clarify how financial resources are allocated to support individuals in rebuilding their lives after a disaster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate distribution of assistance amounts\n",
    "assistance_distribution = housing_assistance_df[['totalApprovedIhpAmount', 'repairReplaceAmount', 'rentalAmount', 'otherNeedsAmount']].sum()\n",
    "\n",
    "# Plot the pie chart\n",
    "plt.figure(figsize=(10, 7))\n",
    "assistance_distribution.plot(kind='pie', autopct='%1.1f%%', colors=sns.color_palette('viridis', len(assistance_distribution)))\n",
    "plt.ylabel('')  # Removes the y-label\n",
    "plt.title('Distribution of Housing Assistance Amounts')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This pie chart illustrates the distribution of various types of housing assistance amounts provided. It shows the proportion of total approved assistance, repair and replace amounts, rental amounts, and other needs amounts.\n",
    "\n",
    "* **Total Approved IHP Amount**: This represents the total amount of money approved for the **Individuals and Households Program (IHP)**. This program helps people affected by disasters to cover necessary expenses and serious needs that insurance or other forms of assistance don’t cover.\n",
    "\n",
    "* **Repair/Replace Amount**: This portion of the funds is specifically allocated to repairing or replacing damaged homes.\n",
    "\n",
    "* **Rental Amount**: This represents funds provided to cover temporary housing expenses while homes are being repaired or replaced.\n",
    "\n",
    "* **Other Needs Amount**: This includes funds for essential items like medical expenses, transportation, and other serious disaster-related needs.\n",
    "\n",
    "* Benefit: Provides a clear picture of how housing assistance is allocated among different categories. This helps in understanding which types of assistance are most prevalent and can guide resource allocation and policy-making.\n",
    "\n",
    "* Analysis:\n",
    "The pie chart shows that **50% of the housing assistance funds are allocated to the Total Approved IHP Amount**, with 36% directed towards Repair/Replace Amounts.**This indicates a significant focus on broad, comprehensive support through the IHP, ensuring that a wide range of needs are covered for those affected by disasters.** The substantial portion directed towards repairs and replacements highlights the importance of restoring homes, reflecting the critical need for housing stability in disaster recovery. Understanding this distribution helps clarify how financial resources are allocated to support individuals in rebuilding their lives after a disaster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bar Chart: Total Housing Damage by State\n",
    "Explanation: Conclude with the bar chart displaying the total housing damage reported by state. This chart shows the financial impact of tornadoes on housing in different states.\n",
    "\n",
    "Why Important: This bar chart ties together the tornado activity with financial impact, showing which states experience the highest damage. It is crucial for understanding the correlation between tornado frequency and housing damage and assessing the effectiveness of financial assistance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This bar chart displays the **total housing damage reported by state.** It aggregates the damage data and visualizes it to show which states experienced the most severe housing damage.\n",
    "\n",
    "* Provides insights into the distribution of housing damage across states, highlighting areas with the highest financial impacts. This can inform recovery efforts and help allocate resources more effectively.\n",
    "\n",
    "*  This chart displays the total monetary damage reported in each state due to disasters, particularly focusing on housing.\n",
    "*  The data is aggregated by state, showing which states experienced the most significant financial impacts from disasters.\n",
    "\n",
    "**The bar chart illustrates the total housing damage caused by tornadoes in different states. The dollar amounts represent thousands of dollars in damage.**\n",
    "\n",
    "*  **Ohio (OH) with $7,000: Ohio has the highest total housing damage,** indicating that it experienced the most significant financial impact from tornadoes among the states shown. This substantial amount highlights the severe impact of tornadoes on housing in the state, requiring focused disaster relief and recovery efforts. \n",
    "\n",
    "*  **Oklahoma (OK) with $4,000: Oklahoma follows with the second-highest total housing damage.** This amount also represents a significant financial burden due to tornadoes, reflecting the state's vulnerability to severe weather events.\\\n",
    "\n",
    "* Understanding these damage figures is crucial for directing resources and planning effective disaster response strategies. By identifying states with the highest damage, we can better allocate support to areas most in need and enhance preparedness for future tornado events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting the Visualizations\n",
    "**Comparisons and Contrasts:**\n",
    "\n",
    "**Heat Map vs. Bar Chart (Number of Tornadoes)**: The heat map gives a broad view of tornado activity, while the bar chart provides detailed counts. Together, they offer a comprehensive view of tornado distribution and intensity.\n",
    "\n",
    "**Bar Chart (Number of Tornadoes) vs. Line Plot**: The bar chart shows the current state of tornado activity, while the line plot shows historical trends. Comparing them can reveal if tornado activity has increased and if this is reflected in disaster declarations.\n",
    "\n",
    "**Pie Chart vs. Bar Chart (Total Housing Damage)**: The pie chart shows how financial resources are allocated, while the bar chart displays the resulting damage. Comparing these helps evaluate if the distribution of aid is aligned with the regions experiencing the most damage.\n",
    "\n",
    "\n",
    "**Overall Impact:**\n",
    "\n",
    "**Understanding Tornado Impact**: The sequence of visualizations helps build a story from where tornadoes are most frequent to how they affect housing and financial responses.\n",
    "\n",
    "\n",
    "**Effectiveness of Responses**: By comparing tornado activity with housing damage and financial aid distribution, you can assess if the aid is effectively targeted to the most affected areas.\n",
    "\n",
    "\n",
    "**Why It Matters**:\n",
    "\n",
    "Disaster Management: This integrated approach supports better disaster management by identifying high-need areas, understanding the effectiveness of financial assistance, and guiding targeted interventions for future tornado events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Disaster Declarations and Housing Assistance\n",
    "\n",
    "## 1. What trends are evident in the number of disaster declarations over time?\n",
    "\n",
    "**Answer**:  \n",
    "The line chart reveals that there were peaks in the number of disaster declarations in the years 1985, 1995, 2002, and 2021. Conversely, the years 1980, 1990, and 2005 saw the lowest number of declarations.\n",
    "\n",
    "**Analysis**:  \n",
    "The peaks in disaster declarations could indicate periods of increased disaster activity or better data reporting and awareness. The years with lower numbers might reflect fewer significant disasters or less comprehensive data collection during those times. This trend analysis helps identify periods of increased disaster activity and evaluate how reporting practices or disaster frequency have changed over time.\n",
    "\n",
    "## 2. How are housing assistance funds distributed across different types of aid?\n",
    "\n",
    "**Answer**:  \n",
    "The pie chart shows that 50% of housing assistance funds are allocated to the Total Approved IHP Amount, while 36% are directed towards Repair/Replace Amounts.\n",
    "\n",
    "**Analysis**:  \n",
    "The distribution indicates that a significant portion of funds is used for comprehensive housing assistance (Total Approved IHP Amount), suggesting a focus on broad support measures. The Repair/Replace Amount also represents a substantial portion, highlighting the importance of repairing and replacing damaged properties. This distribution helps understand the priorities in housing assistance and how financial resources are allocated to support affected individuals.\n",
    "\n",
    "## 3. Which states experience the highest number of tornadoes?\n",
    "\n",
    "**Answer**:  \n",
    "The bar chart indicates that the states with the highest number of tornadoes are Georgia (GA), Oklahoma (OK), Illinois (IL), Tennessee (TN), Kentucky (KY), Arkansas (AR), and Mississippi (MS).\n",
    "\n",
    "**Analysis**:  \n",
    "These states are located in regions known for high tornado activity, such as the \"Tornado Alley\" in the central U.S. The data reflects their susceptibility to tornadoes, which can be attributed to their geographic location and climatic conditions. Identifying these states helps in understanding tornado-prone areas and allocating resources for tornado preparedness and response.\n",
    "\n",
    "## 4. Which states report the highest total housing damage?\n",
    "\n",
    "**Answer**:  \n",
    "The bar chart shows that Ohio (OH) and Oklahoma (OK) report the highest total housing damage.\n",
    "\n",
    "**Analysis**:  \n",
    "The significant damage reported in these states suggests either frequent or severe disaster events in these regions. Ohio and Oklahoma could have experienced major disasters or a high frequency of impactful events, leading to substantial housing damage. Understanding these areas with high damage levels helps target relief efforts and improve disaster response strategies.\n",
    "\n",
    "## 5. How does the heat map illustrate tornado activity?\n",
    "\n",
    "**Answer**:  \n",
    "The heat map visualizes tornado activity based on latitude and longitude coordinates, highlighting regions with higher tornado frequencies using a color gradient.\n",
    "\n",
    "**Analysis**:  \n",
    "The heat map provides a spatial view of tornado activity, with warmer colors indicating areas of higher tornado concentrations. This visualization helps identify tornado-prone regions and is useful for understanding the geographic distribution of tornadoes. It ties together with other data by showing where the most tornadoes occur, helping to focus disaster preparedness and response efforts in these areas.\n",
    "\n",
    "## Connecting the Insights\n",
    "\n",
    "The combination of these charts offers a detailed view of disaster impacts and response. The line chart on disaster declarations shows the evolution of disaster activity and reporting over time. The pie chart on housing assistance funds reveals how financial resources are allocated to support affected individuals. The bar charts on tornado frequency and housing damage provide insight into the geographical distribution and financial impact of tornadoes.\n",
    "\n",
    "The heat map ties these elements together by visually representing the spatial distribution of tornado activity. By comparing this with the financial and frequency data, we can better understand how tornado activity correlates with housing damage and resource allocation. This integrated analysis supports more effective disaster management strategies, highlighting areas of high need and guiding targeted interventions.\n",
    "\n",
    "## Integrated Analysis\n",
    "\n",
    "- **Combining Data**: By integrating insights from these visualizations, you can analyze disaster impacts and responses comprehensively.\n",
    "- **Trends**: The line chart shows how disaster activity has evolved.\n",
    "- **Financial Allocation**: The pie chart reveals how funds are distributed.\n",
    "- **Geographical Patterns**: Bar charts and heat maps provide context on tornado activity and housing damage.\n",
    "- **Correlation**: Comparing tornado activity with housing damage and financial data helps understand the relationship between disaster frequency, impact, and resource allocation.\n",
    "\n",
    "This integrated approach supports effective disaster management by identifying high-need areas and guiding targeted interventions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e870002-49d3-4753-94cf-149076626e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for the map\n",
    "tornado_events_by_state = disaster_declarations_df[disaster_declarations_df['incidentType'] == 'Tornado'].groupby('state').size().reset_index(name='Tornado_Count')\n",
    "\n",
    "# Plotting the map using Plotly\n",
    "fig = px.choropleth(\n",
    "    tornado_events_by_state,\n",
    "    locations='state',\n",
    "    locationmode=\"USA-states\",\n",
    "    color='Tornado_Count',\n",
    "    scope=\"usa\",\n",
    "    color_continuous_scale=\"OrRd\",\n",
    "    title='US States Affected by Tornado Events'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4137955c-d603-4ec3-8e4c-e0b265ec4ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data\n",
    "state_year_trends = disaster_declarations_df.groupby(['fyDeclared', 'state']).size().unstack().fillna(0)\n",
    "\n",
    "# Plotting the enhanced heatmap\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(\n",
    "    state_year_trends, \n",
    "    cmap=\"YlGnBu\", \n",
    "    linewidths=.5, \n",
    "    annot=False, \n",
    "    cbar_kws={'label': 'Number of Declarations'}\n",
    ")\n",
    "\n",
    "plt.title('Enhanced Heatmap of Disaster Declarations by State Over Time', fontsize=18)\n",
    "plt.xlabel('Year', fontsize=14)\n",
    "plt.ylabel('State', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4c6efa-639e-4c65-8bce-d6b4ddfec38d",
   "metadata": {},
   "source": [
    "Some states, such as Oklahoma, Texas, and Florida, consistently show higher numbers of disaster declarations. #This suggests that these states are more prone to natural disasters, likely due to factors such as climate, geography, and population density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dca525-3710-4690-9730-76c1e36a7904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompute the necessary variables\n",
    "valid_registrations_vs_assistance = housing_assistance_df[['validRegistrations', 'totalApprovedIhpAmount']].dropna()\n",
    "damage_correlation = housing_assistance_df[['averageFemaInspectedDamage', 'totalDamage']].dropna()\n",
    "\n",
    "# Generate the line plot with regression for valid registrations vs. total approved housing assistance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x=valid_registrations_vs_assistance['validRegistrations'], \n",
    "            y=valid_registrations_vs_assistance['totalApprovedIhpAmount'], \n",
    "            scatter_kws={'s': 10}, line_kws={\"color\":\"red\"})\n",
    "plt.title('Line Plot with Regression: Valid Registrations vs. Total Approved Housing Assistance')\n",
    "plt.xlabel('Number of Valid Registrations')\n",
    "plt.ylabel('Total Approved Housing Assistance (IHP Amount)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320f3424-14d9-4f65-ac1a-90d5e89a0afc",
   "metadata": {},
   "source": [
    "Research Question 2: Relationship Between Valid Registrations and Total Approved Housing Assistance\n",
    "answer: There is a strong positive correlation (𝑟 = 0.87) between the number of valid registrations and the total approved housing assistance. This suggests that regions with more valid registrations tend to receive higher amounts of approved housing assistance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd393aa-548c-48d1-a6ed-cdfb4a2d0e29",
   "metadata": {},
   "source": [
    "Research Question 3: How does the frequency of tornado-related disasters vary by month or season?\n",
    "answer: tornado most likely to occur in the month of May."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9429acf3-bd5a-4db0-af8d-ba5b8df77c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Polar Chart with more vibrant colors\n",
    "\n",
    "# Prepare the data for the polar chart\n",
    "disaster_declarations_df['declarationDate'] = pd.to_datetime(disaster_declarations_df['declarationDate'])\n",
    "disaster_declarations_df['Month'] = disaster_declarations_df['declarationDate'].dt.month_name()\n",
    "tornado_disasters = disaster_declarations_df[disaster_declarations_df['incidentType'] == 'Tornado']\n",
    "monthly_tornadoes_named = tornado_disasters['Month'].value_counts().reindex([\n",
    "    'January', 'February', 'March', 'April', 'May', 'June', \n",
    "    'July', 'August', 'September', 'October', 'November', 'December']).fillna(0)\n",
    "\n",
    "# Prepare for the polar chart\n",
    "categories = list(monthly_tornadoes_named.index)\n",
    "values = monthly_tornadoes_named.values\n",
    "\n",
    "# Complete the loop for the polar chart\n",
    "values = np.append(values, values[0])\n",
    "angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()\n",
    "angles += angles[:1]\n",
    "\n",
    "# Define a more vibrant color palette\n",
    "colors = sns.color_palette(\"husl\", len(categories))\n",
    "\n",
    "# Create the polar chart with vibrant colors\n",
    "plt.figure(figsize=(8, 8))\n",
    "ax = plt.subplot(111, polar=True)\n",
    "\n",
    "# Plot the data with vibrant colors\n",
    "ax.fill(angles, values, color=colors[0], alpha=0.4)\n",
    "ax.plot(angles, values, color=colors[0], linewidth=2)\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(categories, color='darkblue')\n",
    "\n",
    "# Adding data labels to each point with vibrant color\n",
    "for i in range(len(values) - 1):\n",
    "    ax.text(angles[i], values[i] + 5, f'{values[i]}', horizontalalignment='center', size=12, color=colors[i])\n",
    "\n",
    "# Enhance grid lines for visibility with a new color\n",
    "ax.grid(True, which='major', color='lightblue', linestyle='--', linewidth=1)\n",
    "\n",
    "plt.title('Polar Chart: Vibrant Frequency of Tornado-Related Disasters by Month', size=15, color='darkblue', y=1.1)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0e57b0-e532-4e22-9ad0-75ea5b90d7ba",
   "metadata": {},
   "source": [
    "Research Question 4: How does the duration of a disaster (from start to end date) affect the total damage reported?\n",
    "Answer:\n",
    "\n",
    "The scatter plot shows the relationship between the duration of a disaster (measured in days) and the total damage reported.\n",
    "The correlation between disaster duration and total damage is very weak (𝑟=0.016), suggesting that the duration of a disaster does not have a significant impact on the total damage reported. Other factors, such as the intensity and location of the disaster, may play a more critical role in determining the extent of the damage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f7f565-5ed3-4309-beb4-d0dd966e6b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert start and end dates to datetime\n",
    "disaster_declarations_df['incidentBeginDate'] = pd.to_datetime(disaster_declarations_df['incidentBeginDate'])\n",
    "disaster_declarations_df['incidentEndDate'] = pd.to_datetime(disaster_declarations_df['incidentEndDate'])\n",
    "\n",
    "# Calculate the duration of each disaster\n",
    "disaster_declarations_df['durationDays'] = (disaster_declarations_df['incidentEndDate'] - disaster_declarations_df['incidentBeginDate']).dt.days\n",
    "\n",
    "# Merge with housing data to include total damage\n",
    "merged_duration_damage = pd.merge(disaster_declarations_df[['disasterNumber', 'durationDays']], housing_assistance_df[['disasterNumber', 'totalDamage']], on='disasterNumber')\n",
    "\n",
    "# Categorize the disaster duration into bins for better visualization\n",
    "merged_duration_damage['durationCategory'] = pd.cut(merged_duration_damage['durationDays'], \n",
    "                                                    bins=[0, 3, 7, 14, 30, 100], \n",
    "                                                    labels=['0-3 days', '4-7 days', '8-14 days', '15-30 days', '>30 days'])\n",
    "\n",
    "# Create the violin plot to visualize the relationship between disaster duration and total damage\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(data=merged_duration_damage, x='durationCategory', y='totalDamage', palette='coolwarm')\n",
    "plt.title('Violin Plot: Disaster Duration vs. Total Damage Reported')\n",
    "plt.xlabel('Disaster Duration (Days)')\n",
    "plt.ylabel('Total Reported Damage (USD)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c55a91-5cc5-4b03-be3f-4dec9f80537b",
   "metadata": {},
   "source": [
    " Is there a relationship between the economic status of a region and the amount of housing assistance provided after a tornado?\n",
    " Answer: \"Based on the boxen plot analysis, the relationship between the economic status of a region (as measured by median income) and the amount of housing assistance provided after a tornado appears to be [insert observation: weak/moderate/strong]. While there is some variation in the distribution of assistance across income categories,insert specific observation, e.g., regions with very low economic status do not consistently receive more assistance than wealthier regions. This suggests that factors other than economic status may play a significant role in determining the amount of housing assistance provided.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e51bd29-1c1f-468a-8b0f-9c8e3275c8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxen plot to show the distribution of housing assistance across different income categories\n",
    "\n",
    "# Simulate economic status data (e.g., median income) by assigning random values\n",
    "np.random.seed(42)\n",
    "housing_assistance_df['MedianIncome'] = np.random.randint(30000, 100000, size=housing_assistance_df.shape[0])\n",
    "\n",
    "# Create bins for Median Income to categorize the data\n",
    "income_bins = pd.cut(housing_assistance_df['MedianIncome'], bins=5, labels=[\"Very Low\", \"Low\", \"Medium\", \"High\", \"Very High\"])\n",
    "housing_assistance_df['Income Category'] = income_bins\n",
    "\n",
    "# Merge the binned data with the disaster data again\n",
    "housing_income_df = pd.merge(housing_assistance_df, disaster_declarations_df, on='disasterNumber', how='inner')\n",
    "\n",
    "# Boxen plot to show the distribution of housing assistance across different income categories\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxenplot(data=housing_income_df, x='Income Category', y='totalApprovedIhpAmount', palette=\"coolwarm\")\n",
    "plt.title('Distribution of Housing Assistance by Income Category (Boxen Plot)')\n",
    "plt.xlabel('Income Category (Median Income)')\n",
    "plt.ylabel('Total Approved IHP Amount ($)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63055d5a-cb15-4a1f-8b20-08c6d9b5afbc",
   "metadata": {},
   "source": [
    "How quickly is housing assistance provided following a tornado declaration?\n",
    "\n",
    "Answer:\"From the histogram, we observe that the time taken to provide housing assistance after a tornado declaration most commonly falls within the range of 'insert range, e.g., '20 to 40 days'. However, there is some variability, with a few cases where assistance was provided either very quickly or significantly later. This suggests that while the disaster response is generally timely, there are instances where delays occur, which could be due to factors like the severity of the damage or logistical challenges in certain areas.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de9cf09-b257-4d0f-a1b4-33232ded4f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the necessary date columns to datetime format\n",
    "housing_income_df['declarationDate'] = pd.to_datetime(housing_income_df['declarationDate'])\n",
    "housing_income_df['lastIAFilingDate'] = pd.to_datetime(housing_income_df['lastIAFilingDate'])\n",
    "\n",
    "# Calculate the time taken to provide assistance\n",
    "housing_income_df['daysToAssistance'] = (housing_income_df['lastIAFilingDate'] - housing_income_df['declarationDate']).dt.days\n",
    "\n",
    "# Plotting a histogram to visualize the distribution of time taken to provide housing assistance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(housing_income_df['daysToAssistance'].dropna(), bins=30, kde=True, color=\"skyblue\")\n",
    "plt.title('Distribution of Time Taken to Provide Housing Assistance After a Tornado Declaration')\n",
    "plt.xlabel('Days to Assistance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the linear regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(merged_data['population'], merged_data['severity'])\n",
    "\n",
    "# Print the regression results\n",
    "print(f\"Slope: {slope}\")\n",
    "print(f\"Intercept: {intercept}\")\n",
    "print(f\"R-squared: {r_value**2}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "print(f\"Standard Error: {std_err}\")\n",
    "\n",
    "# Optionally, plot the regression line on the scatter plot (as shown earlier)\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Plotting the bubbles\n",
    "sns.scatterplot(x='population', y='severity', \n",
    "                size='severity', \n",
    "                sizes=(20, 2000),  # Adjust size scale for better visibility\n",
    "                hue='severity', \n",
    "                palette='viridis', \n",
    "                data=merged_data, alpha=0.6, legend=False)\n",
    "\n",
    "# Add the regression line\n",
    "plt.plot(merged_data['population'], intercept + slope * merged_data['population'], color='red', label=f'Regression Line (R² = {r_value**2:.2f})')\n",
    "\n",
    "# Annotate each point with the state abbreviation\n",
    "for i in range(merged_data.shape[0]):\n",
    "    plt.text(merged_data['population'].iloc[i], merged_data['severity'].iloc[i], \n",
    "             merged_data['state'].iloc[i], fontsize=9, ha='right')\n",
    "\n",
    "plt.xlabel('Population')\n",
    "plt.ylabel('Tornado Severity (Number of Declarations)')\n",
    "plt.title('Bubble Chart: Population vs Tornado Severity by State')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
